{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e908dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37cbeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretize_obs(gym.Wrapper):\n",
    "    def __init__(self, env, nvec=10):\n",
    "        super(Discretize_obs, self).__init__(env) #sets self.env\n",
    "        if isinstance(nvec,int): #nvec in each dimention\n",
    "            self.nvec = [nvec]*np.prod(env.observation_space.shape,dtype=int)\n",
    "        else:\n",
    "            self.nvec = nvec\n",
    "        self.nvec = np.array(nvec) #(Nobs,) array\n",
    "        \n",
    "        self.observation_space = gym.spaces.MultiDiscrete(self.nvec)#([self.nvec, self.nvec]) #b)\n",
    "        self.olow, self.ohigh = np.array([-np.pi,-40]), np.array([np.pi,40])\n",
    "\n",
    "    def discretize(self,observation): #b)\n",
    "        # print(\"observation\", type(observation))\n",
    "        # print(\"olow\", type(self.olow), np.array(self.olow))\n",
    "        # print(\"minus\", observation - self.olow)\n",
    "        # print(\"minus2\", np.array(self.ohigh) - np.array(self.olow))\n",
    "        # print((observation - self.olow)/(np.array(self.ohigh) - np.array(self.olow)))\n",
    "        return tuple(((observation - self.olow)/(self.ohigh - self.olow)*self.nvec).astype(int)) #b)\n",
    "        \n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action) #b)\n",
    "        return self.discretize(observation), reward, terminated, truncated, info #b)\n",
    "\n",
    "    def reset(self):\n",
    "        obs, info = self.env.reset()\n",
    "        obs_dis = self.discretize(obs)  #b=)\n",
    "        return obs_dis, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bf9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnbalancedDisk(gym.Env):\n",
    "    '''\n",
    "    UnbalancedDisk\n",
    "    th =            \n",
    "                  +-pi\n",
    "                    |\n",
    "           pi/2   ----- -pi/2\n",
    "                    |\n",
    "                    0  = starting location\n",
    "    '''\n",
    "    def __init__(self, umax=3., dt = 0.025, render_mode='human'):\n",
    "        ############# start do not edit  ################\n",
    "        self.omega0 = 11.339846957335382\n",
    "        self.delta_th = 0\n",
    "        self.gamma = 1.3328339309394384\n",
    "        self.Ku = 28.136158407237073\n",
    "        self.Fc = 6.062729509386865\n",
    "        self.coulomb_omega = 0.001\n",
    "\n",
    "        # self.g = 9.80155078791343\n",
    "        # self.J = 0.000244210523960356\n",
    "        # self.Km = 10.5081817407479\n",
    "        # self.I = 0.0410772235841364\n",
    "        # self.M = 0.0761844495320390\n",
    "        # self.tau = 0.397973147009910\n",
    "        ############# end do not edit ###################\n",
    "\n",
    "        self.umax = umax\n",
    "        self.dt = dt #time step\n",
    " \n",
    "\n",
    "        # change anything here (compilable with the exercise instructions)\n",
    "        self.action_space = spaces.Box(low=-umax,high=umax,shape=tuple()) #continuous\n",
    "        \n",
    "        self.action_space = spaces.Discrete(5) #discrete\n",
    "        # print(self.action_space)\n",
    "        # low = [-float('inf'),-40] \n",
    "        # high = [float('inf'),40]\n",
    "        # aangepast\n",
    "        low = [-np.pi,-40] \n",
    "        high = [np.pi,40]\n",
    "        self.observation_space = spaces.Box(low=np.array(low,dtype=np.float32),high=np.array(high,dtype=np.float32),shape=(2,))\n",
    "        # print(self.observation_space)\n",
    "        nvec = 100\n",
    "        # self.observation_space = tuple(((self.observation_space - low)/(high - low)*nvec).astype(int))\n",
    "        # self.reward_fun = lambda self: np.exp(-(self.th%(2*np.pi)-np.pi)**2/(2*(np.pi/7)**2)) #example reward function, change this!\n",
    "        # self.reward_fun = lambda self: np.cos(self.th) - 0.01 * self.delta_th**2\n",
    "        self.reward_fun = lambda self: abs(self.th)\n",
    "        self.render_mode = render_mode\n",
    "        self.viewer = None\n",
    "        self.u = 0 #for visual\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        #convert action to u\n",
    "        # self.u = action #continuous\n",
    "        self.u = [-3,-1,0,1,3][action] #discrate\n",
    "        # self.u = [-3,3][action] #discrate\n",
    "\n",
    "        ##### Start Do not edit ######\n",
    "        self.u = np.clip(self.u,-self.umax,self.umax)\n",
    "        def f(t,y):\n",
    "            th, omega = y\n",
    "            dthdt = omega\n",
    "            friction = self.gamma*omega + self.Fc*np.tanh(omega/self.coulomb_omega)\n",
    "            domegadt = -self.omega0**2*np.sin(th+self.delta_th) - friction + self.Ku*self.u\n",
    "            return np.array([dthdt, domegadt])\n",
    "        sol = solve_ivp(f,[0,self.dt],[self.th,self.omega]) #integration\n",
    "        self.th, self.omega = sol.y[:,-1]\n",
    "        ##### End do not edit   #####\n",
    "        terminated = abs(self.th % (2 * np.pi) - np.pi) > 0.9 #and abs(self.omega) < 0.\n",
    "        reward = self.reward_fun(self)\n",
    "        if terminated:\n",
    "            # print(\"terminated\")\n",
    "            reward += 10\n",
    "        return self.get_obs(), reward, terminated, False, [self.th, self.omega]\n",
    "         \n",
    "    def reset(self,seed=None, options=None):\n",
    "        self.th = np.random.normal(loc=0,scale=0.001)\n",
    "        self.omega = np.random.normal(loc=0,scale=0.001)\n",
    "        self.u = 0\n",
    "        return self.get_obs(), {}\n",
    "\n",
    "    def get_obs(self):\n",
    "        self.th_noise = self.th + np.random.normal(loc=0,scale=0.001) #do not edit\n",
    "        self.omega_noise = self.omega + np.random.normal(loc=0,scale=0.001) #do not edit\n",
    "        return np.array([self.th_noise, self.omega_noise])\n",
    "\n",
    "    def render(self):\n",
    "        import pygame\n",
    "        from pygame import gfxdraw\n",
    "        \n",
    "        screen_width = 500\n",
    "        screen_height = 500\n",
    "\n",
    "        th = self.th\n",
    "        omega = self.omega #x = self.state\n",
    "\n",
    "        if self.viewer is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.viewer = pygame.display.set_mode((screen_width, screen_height))\n",
    "\n",
    "        self.surf = pygame.Surface((screen_width, screen_height))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "        \n",
    "        gfxdraw.filled_circle( #central blue disk\n",
    "            self.surf,\n",
    "            screen_width//2,\n",
    "            screen_height//2,\n",
    "            int(screen_width/2*0.65*1.3),\n",
    "            (32,60,92),\n",
    "        )\n",
    "        gfxdraw.filled_circle( #small midle disk\n",
    "            self.surf,\n",
    "            screen_width//2,\n",
    "            screen_height//2,\n",
    "            int(screen_width/2*0.06*1.3),\n",
    "            (132,132,126),\n",
    "        )\n",
    "        \n",
    "        from math import cos, sin\n",
    "        r = screen_width//2*0.40*1.3\n",
    "        gfxdraw.filled_circle( #disk\n",
    "            self.surf,\n",
    "            int(screen_width//2-sin(th)*r), #is direction correct?\n",
    "            int(screen_height//2-cos(th)*r),\n",
    "            int(screen_width/2*0.22*1.3),\n",
    "            (155,140,108),\n",
    "        )\n",
    "        gfxdraw.filled_circle( #small nut\n",
    "            self.surf,\n",
    "            int(screen_width//2-sin(th)*r), #is direction correct?\n",
    "            int(screen_height//2-cos(th)*r),\n",
    "            int(screen_width/2*0.22/8*1.3),\n",
    "            (71,63,48),\n",
    "        )\n",
    "        \n",
    "        fname = path.join(path.dirname(__file__), \"clockwise.png\")\n",
    "        self.arrow = pygame.image.load(fname)\n",
    "        if self.u:\n",
    "            if isinstance(self.u, (np.ndarray,list)):\n",
    "                if self.u.ndim==1:\n",
    "                    u = self.u[0]\n",
    "                elif self.u.ndim==0:\n",
    "                    u = self.u\n",
    "                else:\n",
    "                    raise ValueError(f'u={u} is not the correct shape')\n",
    "            else:\n",
    "                u = self.u\n",
    "            arrow_size = abs(float(u)/self.umax*screen_height)*0.25\n",
    "            Z = (arrow_size, arrow_size)\n",
    "            arrow_rot = pygame.transform.scale(self.arrow,Z)\n",
    "            if self.u<0:\n",
    "                arrow_rot = pygame.transform.flip(arrow_rot, True, False)\n",
    "                \n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "        self.viewer.blit(self.surf, (0, 0))\n",
    "        if self.u:\n",
    "            self.viewer.blit(arrow_rot, (screen_width//2-arrow_size//2, screen_height//2-arrow_size//2))\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.flip()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            import pygame\n",
    "\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False\n",
    "            self.viewer = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c86cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnbalancedDisk_sincos(UnbalancedDisk):\n",
    "    \"\"\"docstring for UnbalancedDisk_sincos\"\"\"\n",
    "    def __init__(self, umax=3., dt = 0.025):\n",
    "        super(UnbalancedDisk_sincos, self).__init__(umax=umax, dt=dt)\n",
    "        low = [-1,-1,-40.] \n",
    "        high = [1,1,40.]\n",
    "        self.observation_space = spaces.Box(low=np.array(low,dtype=np.float32),high=np.array(high,dtype=np.float32),shape=(3,))\n",
    "\n",
    "    def get_obs(self):\n",
    "        self.th_noise = self.th + np.random.normal(loc=0,scale=0.001) #do not edit\n",
    "        self.omega_noise = self.omega + np.random.normal(loc=0,scale=0.001) #do not edit\n",
    "        return np.array([np.sin(self.th_noise), np.cos(self.th_noise), self.omega_noise]) #change anything here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ee7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(a):\n",
    "    #argmax([0,1,2,3]) -> 3\n",
    "    #argmax([0,1,2,2]) -> 2 or 3 with equal probability of both (np.argmax would only return 2)\n",
    "    #argmax([0,0,0,0]) -> 0, 1, 2 or 3 with equal probability of each (np.argmax would only return 0)\n",
    "    a = np.array(a)\n",
    "    return np.random.choice(np.arange(a.shape[0],dtype=int)[a==np.max(a)])\n",
    "\n",
    "\n",
    "\n",
    "def Qlearn(env, nsteps=5000, callbackfeq=100, alpha=0.5,eps=0.2, gamma=0.99): # was alpha = 0.2\n",
    "    from collections import defaultdict\n",
    "    Qmat = defaultdict(float) #any new argument set to zero\n",
    "    env_time = env\n",
    "    # env_time = env.unwrapped\n",
    "    while not isinstance(env_time,gym.wrappers.TimeLimit):\n",
    "        env_time = env_time.env\n",
    "    ep_lengths = []\n",
    "    ep_lengths_steps = []\n",
    "    rewards = []\n",
    "    omegas = []\n",
    "    \n",
    "    obs, info = env.reset()\n",
    "    print('goal reached time:')\n",
    "    for z in range(nsteps):\n",
    "\n",
    "        if np.random.uniform()<eps:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = argmax([Qmat[obs,i] for i in range(env.action_space.n)])\n",
    "\n",
    "        obs_new, reward, terminated, truncated, info = env.step(action)\n",
    "        # print(\"reward\", reward, \"   info\", info)\n",
    "        rewards.append(reward)\n",
    "        omegas.append(info[1])\n",
    "        if terminated: #terminal state and not by timeout\n",
    "            #saving results:\n",
    "            print(env_time._elapsed_steps, end=' ')\n",
    "            ep_lengths.append(env_time._elapsed_steps)\n",
    "            ep_lengths_steps.append(z)\n",
    "            # print(\"terminated\") # verwijderen\n",
    "            \n",
    "            #updating Qmat:\n",
    "            A = reward - Qmat[obs,action] # adventage or TD\n",
    "            Qmat[obs,action] += alpha*A\n",
    "            obs, info = env.reset()\n",
    "        else: #not terminal\n",
    "            A = reward + gamma*max(Qmat[obs_new, action_next] for action_next in range(env.action_space.n)) - Qmat[obs,action]\n",
    "            Qmat[obs,action] += alpha*A\n",
    "            obs = obs_new\n",
    "            \n",
    "            if truncated: #terminal by truncation with timeout\n",
    "                #saving results:\n",
    "                ep_lengths.append(env_time._elapsed_steps)\n",
    "                ep_lengths_steps.append(z)\n",
    "                print('out', end=' ')\n",
    "                \n",
    "                #reset:\n",
    "                obs, info = env.reset()\n",
    "    print()\n",
    "    \n",
    "    return Qmat, np.array(ep_lengths_steps), np.array(ep_lengths), [rewards, omegas]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def roll_mean(ar,start=2000,N=50):\n",
    "    s = 1-1/N\n",
    "    k = start\n",
    "    out = np.zeros(ar.shape)\n",
    "    for i,a in enumerate(ar):\n",
    "        k = s*k + (1-s)*a\n",
    "        out[i] = k\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa48699",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmats = {}\n",
    "for nvec in [40]: #c) # was 5,10,20,40,80\n",
    "    max_episode_steps = 1000 #c) # was 1000\n",
    "    env = UnbalancedDisk(dt=0.025)\n",
    "    env = gym.wrappers.TimeLimit(env,max_episode_steps=max_episode_steps) \n",
    "    env = Discretize_obs(env, nvec=nvec)\n",
    "\n",
    "    print('nvec=',nvec) #c)\n",
    "    Qmat, ep_lengths_steps, ep_lengths, info = Qlearn(env, nsteps=50_000, callbackfeq=5000) #c=) # was 400_000\n",
    "    rewards = info[0]\n",
    "    omegas = info[1]\n",
    "    # print(\"omegas\", omegas)\n",
    "    plt.plot(ep_lengths_steps,roll_mean(ep_lengths,start=max_episode_steps),label=str(nvec)) #c)\n",
    "    Qmats[nvec] = Qmat #save\n",
    "plt.legend() #c)\n",
    "plt.show() #c)\n",
    "plt.plot(rewards)\n",
    "# plt.plot(omegas)\n",
    "# plt.legend(\"rewards\", \"omegas\")\n",
    "plt.show()\n",
    "plt.plot(omegas)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "with open(\"qmats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Qmats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
